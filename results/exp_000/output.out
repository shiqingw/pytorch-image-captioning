nohup: ignoring input
==> device:  cuda
==> Epoch: 000
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [27,0,0] Assertion `t >= 0 && t < n_classes` failed.
Traceback (most recent call last):
  File "main.py", line 237, in <module>
    train(epoch, train_loss)
  File "main.py", line 155, in train
    loss = loss_fcn(y_pred, y.long())
  File "/data/shiqing/venv_py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/data/shiqing/venv_py37/lib/python3.7/site-packages/torch/nn/modules/loss.py", line 1176, in forward
    label_smoothing=self.label_smoothing)
  File "/data/shiqing/venv_py37/lib/python3.7/site-packages/torch/nn/functional.py", line 3026, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: numel: integer multiplication overflow
